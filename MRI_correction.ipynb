{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de neurones unrolled pour l'IRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les lignes suivantes permettent d'installer une bibliothèque pour le calcul de la Transformée de Fourier Non-Uniforme (NUFFT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Bindings-NUFFT-pytorch'...\n",
      "remote: Enumerating objects: 61, done.\u001b[K\n",
      "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 61 (delta 36), reused 53 (delta 32), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (61/61), 18.64 KiB | 578.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/albangossard/Bindings-NUFFT-pytorch\n",
    "![ -e nufftbindings/ ] && rm -r -f nufftbindings/\n",
    "!mv Bindings-NUFFT-pytorch/nufftbindings/ ./\n",
    "!rm -r -f Bindings-NUFFT-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Téléchargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: tqdm in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from gdown) (4.62.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from gdown) (4.10.0)\n",
      "Requirement already satisfied: filelock in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from gdown) (3.4.0)\n",
      "Requirement already satisfied: requests[socks] in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: six in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from requests[socks]->gdown) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/alban/anaconda3/envs/TORCHNUFFT2/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=17k1CYZ4bgbv6q4T4q_zSmEFhwcWlDSVZ\n",
      "To: /media/DATA/Alban/Course-inverse-problems-and-unrolled-networks/fastMRI.tar.gz\n",
      "100%|██████████████████████████████████████| 3.32G/3.32G [00:37<00:00, 87.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!gdown https://drive.google.com/uc?id=17k1CYZ4bgbv6q4T4q_zSmEFhwcWlDSVZ\n",
    "!tar -xzf fastMRI.tar.gz\n",
    "!rm -r -f data/fastMRI/\n",
    "!mv fastMRI/ data/fastMRI/\n",
    "!rm fastMRI.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from DIDN import DIDN\n",
    "import nufftbindings.kbnufft as nufft\n",
    "import dataLoaderfastMRI\n",
    "import scripts.metrics as metrics\n",
    "from scripts.recon import cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10320, 2]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "nx = ny = 320\n",
    "Nbatch = 8\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "xi = torch.tensor(np.load(\"data/xi_10.npy\")).to(device)\n",
    "print(xi.shape, xi.dtype)\n",
    "K = xi.shape[0]\n",
    "\n",
    "nufft.nufft.set_dims(K, (nx, ny), device, Nb=Nbatch)\n",
    "\n",
    "nufft.nufft.precompute(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb images in training dataset: 3619\n",
      "nb images in testing dataset: 705\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataLoaderfastMRI.fastMRIdatasetKnee(train=True)\n",
    "dataset_test = dataLoaderfastMRI.fastMRIdatasetKnee(train=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=Nbatch, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=Nbatch, shuffle=True)\n",
    "print('nb images in training dataset:',len(dataset_train))\n",
    "print('nb images in testing dataset:',len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction réalisant l'optimisation du modèle sur une epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optim, train_loader, xi, verbose=2, writer=None):\n",
    "    model.train()\n",
    "    Niter = len(train_loader)\n",
    "    if verbose>=2:\n",
    "        iterfn = lambda x: x\n",
    "    else:\n",
    "        print(\"Training epoch {:<3}\".format(epoch))\n",
    "        iterfn = tqdm\n",
    "    for nit, data in enumerate(iterfn(train_loader)):\n",
    "        f = data.to(device).type(torch.complex64)\n",
    "        optim.zero_grad()\n",
    "        y = nufft.forward(xi, f)/np.sqrt(nx*ny)\n",
    "        y = y+torch.randn_like(y)*1e0/np.sqrt(nx*ny)\n",
    "        f_tilde = model(y)\n",
    "        loss = metrics.l2err(f, f_tilde).mean()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        psnr = metrics.psnr(f, f_tilde)\n",
    "        mean_psnr = psnr.mean()\n",
    "        if verbose>=2:\n",
    "            print(\"  Epoch {:<3} It {:<4}/{:<4} cost={:1.3e}  PSNR={:.3f}\".format(epoch, nit, Niter, loss, mean_psnr))\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('loss/train', loss.item(), epoch*Niter+nit)\n",
    "            writer.add_scalar('psnr/train', mean_psnr.item(), epoch*Niter+nit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder une fonction testant le modèle sur tout le jeu de données test et qui renvoie un array numpy des PSNR associés à chaque image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, xi):\n",
    "    model.eval()\n",
    "    test_psnr = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            f = data.to(device).type(torch.complex64)\n",
    "            y = nufft.forward(xi, f)/np.sqrt(nx*ny)\n",
    "            f_tilde = model(y)\n",
    "            psnr = metrics.psnr(f, f_tilde)\n",
    "            for p in psnr:\n",
    "                test_psnr.append(p.item())\n",
    "    return np.array(test_psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémenter une fonction appelant $Nepoch$ fois la fonction train et test. Ne pas oublier d'appeler un éventuel scheduler passé en argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, optim, train_loader, test_loader, xi, scheduler=None, Nepoch=10, verbose=1, writer=None):\n",
    "    for epoch in range(Nepoch):\n",
    "        train(epoch, model, optim, train_loader, xi, verbose=verbose, writer=writer)\n",
    "        psnr = test(model, test_loader, xi)\n",
    "        mean_psnr = psnr.mean()\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('psnr/test', mean_psnr.item(), epoch)\n",
    "        if verbose:\n",
    "            print(\"  Epoch {:<3}  PSNR={:.3f}\".format(epoch, mean_psnr))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructeur adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIAdj(torch.nn.Module):\n",
    "    def __init__(self, nufft, xi):\n",
    "        super(MRIAdj, self).__init__()\n",
    "        self.nufft = nufft\n",
    "        self.xi = torch.nn.Parameter(xi, requires_grad=False)\n",
    "        self.net = DIDN(2, 2, num_chans=32, bias=True)\n",
    "    def forward(self, y):\n",
    "        fhat = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)\n",
    "        fhat = torch.cat((fhat.real.unsqueeze(1), fhat.imag.unsqueeze(1)), axis=1).type(torch.float32)\n",
    "        f_tilde = self.net(fhat)\n",
    "        f_tilde = f_tilde[:,0]+1j*f_tilde[:,1]\n",
    "        return f_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adj = MRIAdj(nufft, xi).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_adj.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [01:14<00:00,  6.11it/s]\n",
      "100%|██████████| 89/89 [00:06<00:00, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 0    PSNR=19.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('tblogs/mri/adj')\n",
    "run(model_adj, optim, train_loader, test_loader, xi, Nepoch=1, verbose=1, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled forward-backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIUnrolledFB(nn.Module):\n",
    "    def __init__(self, nufft, xi, Nunrolled, num_chans_net=32, bias=True):\n",
    "        super(MRIUnrolledFB, self).__init__()\n",
    "        self.Nunrolled = Nunrolled\n",
    "        self.nufft = nufft\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "        self.net = nn.ModuleList([DIDN(2, 2, num_chans=num_chans_net, bias=bias) for k in range(self.Nunrolled)])\n",
    "    def change_xi(self, xi):\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "    def precompute(self, f):\n",
    "        x=torch.ones_like(f[:1])\n",
    "        normx = x.pow(2).sum().sqrt()\n",
    "        for i in range(100):\n",
    "            x = x/normx\n",
    "            x = self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, x))/(nx*ny)\n",
    "            normx = x.abs().pow(2).sum().sqrt()\n",
    "        self.gamma = 1/normx\n",
    "    def forward(self, y):\n",
    "        z = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)\n",
    "        for k in range(self.Nunrolled):\n",
    "            grad = self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, z)/np.sqrt(nx*ny)-y)/np.sqrt(nx*ny)\n",
    "            xhat = z-self.gamma*grad\n",
    "            xhat = torch.cat((xhat.real.unsqueeze(1), xhat.imag.unsqueeze(1)), axis=1).type(torch.float32)\n",
    "            z = self.net[k](xhat)\n",
    "            z = z[:,0]+1j*z[:,1]\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nunrolled = 6\n",
    "model_fb = MRIUnrolledFB(nufft, xi, Nunrolled).to(device)\n",
    "model_fb.precompute(next(iter(train_loader)).to(device).type(torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_fb.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [09:45<00:00,  1.29s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 0    PSNR=28.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('tblogs/mri/unrolled_fb')\n",
    "run(model_fb, optim, train_loader, test_loader, xi, Nepoch=1, verbose=1, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIUnrolledADMM(nn.Module):\n",
    "    def __init__(self, nufft, xi, Nunrolled, nitermaxcg, num_chans_net=32, bias=True, beta=1.):\n",
    "        super(MRIUnrolledADMM, self).__init__()\n",
    "        self.Nunrolled = Nunrolled\n",
    "        self.nufft = nufft\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "        self.net = nn.ModuleList([DIDN(2, 2, num_chans=num_chans_net, bias=bias) for k in range(self.Nunrolled)])\n",
    "        self.beta = beta\n",
    "        self.nitermaxcg = nitermaxcg\n",
    "    def change_xi(self, xi):\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "    def precompute(self, f):\n",
    "        x=torch.ones_like(f[:1])\n",
    "        normx = x.pow(2).sum().sqrt()\n",
    "        for i in range(100):\n",
    "            x = x/normx\n",
    "            x = self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, x))/(nx*ny)\n",
    "            normx = x.abs().pow(2).sum().sqrt()\n",
    "        self.gamma = 1/normx\n",
    "    def _Cop(self, x):\n",
    "        return self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, x))/(nx*ny) + self.beta*x\n",
    "    def forward(self, y):\n",
    "        x = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)\n",
    "        z = x.clone()\n",
    "        mu = torch.zeros_like(x)\n",
    "        for k in range(self.Nunrolled):\n",
    "            # x step\n",
    "            rhs = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)+self.beta*z-mu\n",
    "            x, _ = cg(self._Cop, rhs, self.nitermaxcg)\n",
    "\n",
    "            # z step\n",
    "            tmp = torch.cat(((x+mu/self.beta).real.unsqueeze(1), (x+mu/self.beta).imag.unsqueeze(1)), axis=1).type(torch.float32)\n",
    "            z = self.net[k](tmp)\n",
    "            z = z[:,0]+1j*z[:,1]\n",
    "\n",
    "            # mu step\n",
    "            mu = mu+self.beta*(x-z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nunrolled = 5\n",
    "nitermaxcg = 10\n",
    "model_admm = MRIUnrolledADMM(nufft, xi, Nunrolled, nitermaxcg).to(device)\n",
    "model_admm.precompute(next(iter(train_loader)).to(device).type(torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_admm.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/mri/unrolled_admm')\n",
    "run(model_admm, optim, train_loader, test_loader, xi, Nepoch=1, verbose=2, writer=writer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4b19712d075b9b5e34153a3b0fd4a3ae1a679c3d7d133e9e5f694ef7287dc92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
