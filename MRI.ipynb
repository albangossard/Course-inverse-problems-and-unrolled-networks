{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/albangossard/Bindings-NUFFT-pytorch\n",
    "!mv Bindings-NUFFT-pytorch/nufftbindings/ ./\n",
    "!rm -r Bindings-NUFFT-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O fastMRI.tar.gz \"https://drive.google.com/uc?export=download&id=17k1CYZ4bgbv6q4T4q_zSmEFhwcWlDSVZ\"\n",
    "!tar -xzf fastMRI.tar.gz\n",
    "!mv fastMRI/ data/fastMRI/\n",
    "!rm fastMRI.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from DIDN import DIDN\n",
    "import nufftbindings.pykeops as nufft\n",
    "import dataLoaderfastMRI\n",
    "import scripts.metrics as metrics\n",
    "from scripts.recon import cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = ny = 320\n",
    "Nbatch = 8\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "xi = torch.tensor(np.load(\"data/xi_10.npy\")).to(device)\n",
    "print(xi.shape, xi.dtype)\n",
    "K = xi.shape[0]\n",
    "\n",
    "nufft.nufft.set_dims(K, (nx, ny), device, Nb=Nbatch)\n",
    "\n",
    "nufft.nufft.precompute(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataLoaderfastMRI.fastMRIdatasetKnee(train=True)\n",
    "dataset_test = dataLoaderfastMRI.fastMRIdatasetKnee(train=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=Nbatch, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=Nbatch, shuffle=True)\n",
    "print('nb images in training dataset:',len(dataset_train))\n",
    "print('nb images in testing dataset:',len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optim, train_loader, xi, verbose=2, writer=None):\n",
    "    model.train()\n",
    "    Niter = len(train_loader)\n",
    "    if verbose>=2:\n",
    "        iterfn = lambda x: x\n",
    "    else:\n",
    "        print(\"Training epoch {:<3}\".format(epoch))\n",
    "        iterfn = tqdm\n",
    "    for nit, data in enumerate(iterfn(train_loader)):\n",
    "        f = data.to(device).type(torch.complex64)\n",
    "        optim.zero_grad()\n",
    "        y = nufft.forward(xi, f)/np.sqrt(nx*ny)\n",
    "        y = y+torch.randn_like(y)*1e0/np.sqrt(nx*ny)\n",
    "        f_tilde = model(y)\n",
    "        loss = metrics.l2err(f, f_tilde).mean()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        psnr = metrics.psnr(f, f_tilde)\n",
    "        mean_psnr = psnr.mean()\n",
    "        if verbose>=2:\n",
    "            print(\"  Epoch {:<3} It {:<4}/{:<4} cost={:1.3e}  PSNR={:.3f}\".format(epoch, nit, Niter, loss, mean_psnr))\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('loss/train', loss.item(), epoch*Niter+nit)\n",
    "            writer.add_scalar('psnr/train', mean_psnr.item(), epoch*Niter+nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, xi):\n",
    "    model.eval()\n",
    "    test_psnr = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            f = data.to(device).type(torch.complex64)\n",
    "            y = nufft.forward(xi, f)/np.sqrt(nx*ny)\n",
    "            f_tilde = model(y)\n",
    "            psnr = metrics.psnr(f, f_tilde)\n",
    "            for p in psnr:\n",
    "                test_psnr.append(p.item())\n",
    "    return np.array(test_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, optim, train_loader, test_loader, xi, scheduler=None, Nepoch=10, verbose=1, writer=None):\n",
    "    for epoch in range(Nepoch):\n",
    "        train(epoch, model, optim, train_loader, xi, verbose=verbose, writer=writer)\n",
    "        psnr = test(model, test_loader, xi)\n",
    "        mean_psnr = psnr.mean()\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('psnr/test', mean_psnr.item(), epoch)\n",
    "        if verbose:\n",
    "            print(\"  Epoch {:<3}  PSNR={:.3f}\".format(epoch, mean_psnr))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructeur adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIAdj(torch.nn.Module):\n",
    "    def __init__(self, nufft, xi):\n",
    "        super(MRIAdj, self).__init__()\n",
    "        self.nufft = nufft\n",
    "        self.xi = torch.nn.Parameter(xi, requires_grad=False)\n",
    "        self.net = DIDN(2, 2, num_chans=32, bias=True)\n",
    "    def forward(self, y):\n",
    "        fhat = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)\n",
    "        fhat = torch.cat((fhat.real.unsqueeze(1), fhat.imag.unsqueeze(1)), axis=1)\n",
    "        f_tilde = self.net(fhat)\n",
    "        f_tilde = f_tilde[:,0]+1j*f_tilde[:,1]\n",
    "        return f_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adj = MRIAdj(nufft, xi).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_adj.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/mri/adj')\n",
    "run(model_adj, optim, train_loader, test_loader, xi, Nepoch=1, verbose=1, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled forward-backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIUnrolledFB(nn.Module):\n",
    "    def __init__(self, nufft, xi, Nunrolled, num_chans_net=32, bias=True):\n",
    "        super(MRIUnrolledFB, self).__init__()\n",
    "        self.Nunrolled = Nunrolled\n",
    "        self.nufft = nufft\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "        self.net = nn.ModuleList([DIDN(2, 2, num_chans=num_chans_net, bias=bias) for k in range(self.Nunrolled)])\n",
    "    def change_xi(self, xi):\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "    def precompute(self, f):\n",
    "        x=torch.ones_like(f[:1])\n",
    "        normx = x.pow(2).sum().sqrt()\n",
    "        for i in range(100):\n",
    "            x = x/normx\n",
    "            x = self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, x))/(nx*ny)\n",
    "            normx = x.abs().pow(2).sum().sqrt()\n",
    "        self.gamma = 1/normx\n",
    "    def forward(self, y):\n",
    "        z = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)\n",
    "        for k in range(self.Nunrolled):\n",
    "            grad = self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, z)/np.sqrt(nx*ny)-y)/np.sqrt(nx*ny)\n",
    "            xhat = z-self.gamma*grad\n",
    "            xhat = torch.cat((xhat.real.unsqueeze(1), xhat.imag.unsqueeze(1)), axis=1)\n",
    "            z = self.net[k](xhat)\n",
    "            z = z[:,0]+1j*z[:,1]\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nunrolled = 6\n",
    "model_fb = MRIUnrolledFB(nufft, xi, Nunrolled).to(device)\n",
    "model_fb.precompute(next(iter(train_loader)).to(device).type(torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_fb.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/mri/unrolled_fb')\n",
    "run(model_fb, optim, train_loader, test_loader, xi, Nepoch=1, verbose=1, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIUnrolledADMM(nn.Module):\n",
    "    def __init__(self, nufft, xi, Nunrolled, nitermaxcg, num_chans_net=32, bias=True, beta=1.):\n",
    "        super(MRIUnrolledADMM, self).__init__()\n",
    "        self.Nunrolled = Nunrolled\n",
    "        self.nufft = nufft\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "        self.net = nn.ModuleList([DIDN(2, 2, num_chans=num_chans_net, bias=bias) for k in range(self.Nunrolled)])\n",
    "        self.beta = beta\n",
    "        self.nitermaxcg = nitermaxcg\n",
    "    def change_xi(self, xi):\n",
    "        self.xi = nn.Parameter(xi, requires_grad=False)\n",
    "    def precompute(self, f):\n",
    "        x=torch.ones_like(f[:1])\n",
    "        normx = x.pow(2).sum().sqrt()\n",
    "        for i in range(100):\n",
    "            x = x/normx\n",
    "            x = self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, x))/(nx*ny)\n",
    "            normx = x.abs().pow(2).sum().sqrt()\n",
    "        self.gamma = 1/normx\n",
    "    def _Cop(self, x):\n",
    "        return self.nufft.adjoint(self.xi, self.nufft.forward(self.xi, x))/(nx*ny) + self.beta*x\n",
    "    def forward(self, y):\n",
    "        x = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)\n",
    "        z = x.clone()\n",
    "        mu = torch.zeros_like(x)\n",
    "        for k in range(self.Nunrolled):\n",
    "            # x step\n",
    "            rhs = self.nufft.adjoint(self.xi, y)/np.sqrt(nx*ny)+self.beta*z-mu\n",
    "            x, _ = cg(self._Cop, rhs, self.nitermaxcg)\n",
    "\n",
    "            # z step\n",
    "            tmp = torch.cat(((x+mu/self.beta).real.unsqueeze(1), (x+mu/self.beta).imag.unsqueeze(1)), axis=1)\n",
    "            z = self.net[k](tmp)\n",
    "            z = z[:,0]+1j*z[:,1]\n",
    "\n",
    "            # mu step\n",
    "            mu = mu+self.beta*(x-z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nunrolled = 5\n",
    "nitermaxcg = 20\n",
    "model_admm = MRIUnrolledADMM(nufft, xi, Nunrolled, nitermaxcg).to(device)\n",
    "model_admm.precompute(next(iter(train_loader)).to(device).type(torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_admm.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/mri/unrolled_admm')\n",
    "run(model_admm, optim, train_loader, test_loader, xi, Nepoch=1, verbose=2, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4b19712d075b9b5e34153a3b0fd4a3ae1a679c3d7d133e9e5f694ef7287dc92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
