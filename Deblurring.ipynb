{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from DIDN import DIDN\n",
    "import scripts.metrics as metrics\n",
    "from scripts.recon import cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch_size_test = 64\n",
    "nchans = 3\n",
    "nx = ny = 96\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "noiselevel = 3e-2\n",
    "kernelsize = 11\n",
    "sigma = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/mnt/aa2ba8f5-aaff-41d7-afcc-5910a15863df/STL10_dataset'\n",
    "# root = '/media/DATA/STL10_dataset'\n",
    "\n",
    "\n",
    "def normalize(tensor):\n",
    "    mini = tensor.amin(axis=(0,1,2), keepdim=True)\n",
    "    maxi = tensor.amax(axis=(0,1,2), keepdim=True)\n",
    "    return (tensor-mini)/(maxi-mini)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((nx, ny)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(normalize),\n",
    "])\n",
    "dataset_train = datasets.STL10(root=root, split=\"train\", transform=transform, download=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataset_test = datasets.STL10(root=root, split=\"test\", transform=transform, download=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size_test, shuffle=True)\n",
    "print('nb images in training dataset:',len(dataset_train))\n",
    "print('nb images in testing dataset:',len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_coord = torch.arange(kernelsize)\n",
    "x_grid = x_coord.repeat(kernelsize).view(kernelsize, kernelsize)\n",
    "y_grid = x_grid.t()\n",
    "mean = (kernelsize - 1)/2.\n",
    "\n",
    "\n",
    "quadform = ((x_grid-mean)**2+(y_grid-mean)**2)/(2*sigma**2)\n",
    "gaussian_kernel = torch.exp(-0.5*quadform.view(kernelsize, kernelsize))\n",
    "gaussian_kernel = gaussian_kernel/torch.sum(gaussian_kernel)\n",
    "gaussian_kernel = gaussian_kernel.view(1, 1, kernelsize, kernelsize)\n",
    "gaussian_kernel = gaussian_kernel.repeat(nchans, 1, 1, 1).to(device)\n",
    "print(gaussian_kernel.shape)\n",
    "\n",
    "plt.figure(0)\n",
    "c=plt.imshow(gaussian_kernel[0,0].cpu())\n",
    "plt.colorbar(c)\n",
    "plt.show()\n",
    "\n",
    "f = next(iter(train_loader))[0].to(device)\n",
    "\n",
    "f_conv = nn.functional.conv2d(f, gaussian_kernel, groups=nchans, padding=(kernelsize-1)//2)\n",
    "f_noise = f_conv+torch.randn_like(f_conv)*noiselevel\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(f[0].cpu().permute(1,2,0))\n",
    "plt.figure(2)\n",
    "plt.imshow(f_conv[0].cpu().permute(1,2,0))\n",
    "plt.figure(3)\n",
    "plt.imshow(f_noise[0].cpu().permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optim, train_loader, verbose=2, writer=None):\n",
    "    model.train()\n",
    "    Niter = len(train_loader)\n",
    "    if verbose>=2:\n",
    "        iterfn = lambda x: x\n",
    "    else:\n",
    "        print(\"Training epoch {:<3}\".format(epoch))\n",
    "        iterfn = tqdm\n",
    "    for nit, data in enumerate(iterfn(train_loader)):\n",
    "        f = data[0].to(device)\n",
    "        optim.zero_grad()\n",
    "        blurred = model.blur(f) + torch.randn_like(f)*noiselevel\n",
    "        f_tilde = model(blurred)\n",
    "        loss = metrics.l2err(f, f_tilde).mean()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        psnr = metrics.psnr(f, f_tilde)\n",
    "        mean_psnr = psnr.mean()\n",
    "        if verbose>=2:\n",
    "            print(\"  Epoch {:<3} It {:<4}/{:<4} cost={:1.3e}  PSNR={:.3f}\".format(epoch, nit, Niter, loss, mean_psnr))\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('loss/train', loss.item(), epoch*Niter+nit)\n",
    "            writer.add_scalar('psnr/train', mean_psnr.item(), epoch*Niter+nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_psnr = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            f = data[0].to(device)\n",
    "            blurred = model.blur(f)\n",
    "            f_tilde = model(blurred)\n",
    "            loss = metrics.l2err(f, f_tilde).mean()\n",
    "            psnr = metrics.psnr(f, f_tilde)\n",
    "            for p in psnr:\n",
    "                test_psnr.append(p.item())\n",
    "    return np.array(test_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, optim, train_loader, test_loader, scheduler=None, Nepoch=10, verbose=1, writer=None):\n",
    "    for epoch in range(Nepoch):\n",
    "        train(epoch, model, optim, train_loader, verbose=verbose, writer=writer)\n",
    "        psnr = test(model, test_loader)\n",
    "        mean_psnr = psnr.mean()\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('psnr/test', mean_psnr.item(), epoch)\n",
    "        if verbose:\n",
    "            print(\"  Epoch {:<3}  PSNR={:.3f}\".format(epoch, mean_psnr))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructeur adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurAdj(nn.Module):\n",
    "    def __init__(self, gaussian_kernel, num_chans_net=32, bias=True):\n",
    "        super(DeblurAdj, self).__init__()\n",
    "        self.gaussian_kernel = nn.Parameter(gaussian_kernel, requires_grad=False)\n",
    "        self.nchans = gaussian_kernel.shape[0]\n",
    "        self.kernelsize = gaussian_kernel.shape[2]\n",
    "        self.net = DIDN(self.nchans, self.nchans, num_chans=num_chans_net, bias=bias)\n",
    "    def blur(self, f):\n",
    "        return nn.functional.conv2d(f, self.gaussian_kernel, groups=self.nchans, padding=(self.kernelsize-1)//2)\n",
    "    def blur_transpose(self, y):\n",
    "        return nn.functional.conv_transpose2d(y, self.gaussian_kernel, groups=self.nchans, padding=(self.kernelsize-1)//2)\n",
    "    def forward(self, y):\n",
    "        f_tilde = self.net(self.blur_transpose(y))\n",
    "        return f_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adj = DeblurAdj(gaussian_kernel, num_chans_net=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_adj.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/deblurring/adj')\n",
    "run(model_adj, optim, train_loader, test_loader, Nepoch=1, verbose=2, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled forward-backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurUnrolledFB(nn.Module):\n",
    "    def __init__(self, gaussian_kernel, Nunrolled, num_chans_net=32, bias=True):\n",
    "        super(DeblurUnrolledFB, self).__init__()\n",
    "        self.Nunrolled = Nunrolled\n",
    "        self.gaussian_kernel = nn.Parameter(gaussian_kernel, requires_grad=False)\n",
    "        self.nchans = gaussian_kernel.shape[0]\n",
    "        self.kernelsize = gaussian_kernel.shape[2]\n",
    "        self.net = nn.ModuleList([DIDN(self.nchans, self.nchans, num_chans=num_chans_net, bias=bias) for k in range(self.Nunrolled)])\n",
    "    def precompute(self, f):\n",
    "        x=torch.ones_like(f[:1])\n",
    "        normx = x.pow(2).sum().sqrt()\n",
    "        for i in range(100):\n",
    "            x = x/normx\n",
    "            x = self.blur_transpose(self.blur(x))\n",
    "            normx = x.pow(2).sum().sqrt()\n",
    "        self.gamma = 1/normx\n",
    "    def blur(self, f):\n",
    "        return nn.functional.conv2d(f, self.gaussian_kernel, groups=self.nchans, padding=(self.kernelsize-1)//2)\n",
    "    def blur_transpose(self, y):\n",
    "        return nn.functional.conv_transpose2d(y, self.gaussian_kernel, groups=self.nchans, padding=(self.kernelsize-1)//2)\n",
    "    def forward(self, y):\n",
    "        z = self.blur_transpose(y)\n",
    "        for k in range(self.Nunrolled):\n",
    "            grad = self.blur_transpose(self.blur(z)-y)\n",
    "            xhat = z-self.gamma*grad\n",
    "            z = self.net[k](xhat)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fb = DeblurUnrolledFB(gaussian_kernel, 10, num_chans_net=32).to(device)\n",
    "model_fb.precompute(next(iter(train_loader))[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_fb.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/deblurring/unrolled_fb')\n",
    "run(model_fb, optim, train_loader, test_loader, Nepoch=1, verbose=2, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolled ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurUnrolledADMM(nn.Module):\n",
    "    def __init__(self, gaussian_kernel, Nunrolled, nitermaxcg, num_chans_net=32, bias=True, beta=1.):\n",
    "        super(DeblurUnrolledADMM, self).__init__()\n",
    "        self.Nunrolled = Nunrolled\n",
    "        self.gaussian_kernel = nn.Parameter(gaussian_kernel, requires_grad=False)\n",
    "        self.nchans = gaussian_kernel.shape[0]\n",
    "        self.kernelsize = gaussian_kernel.shape[2]\n",
    "        self.net = nn.ModuleList([DIDN(self.nchans, self.nchans, num_chans=num_chans_net, bias=bias) for k in range(self.Nunrolled)])\n",
    "        self.beta = beta\n",
    "        self.nitermaxcg = nitermaxcg\n",
    "    def precompute(self, f):\n",
    "        x=torch.ones_like(f[:1])\n",
    "        normx = x.pow(2).sum().sqrt()\n",
    "        for i in range(100):\n",
    "            x = x/normx\n",
    "            x = self.blur_transpose(self.blur(x))\n",
    "            normx = x.pow(2).sum().sqrt()\n",
    "        self.gamma = 1/normx\n",
    "    def blur(self, f):\n",
    "        return nn.functional.conv2d(f, self.gaussian_kernel, groups=self.nchans, padding=(self.kernelsize-1)//2)\n",
    "    def blur_transpose(self, y):\n",
    "        return nn.functional.conv_transpose2d(y, self.gaussian_kernel, groups=self.nchans, padding=(self.kernelsize-1)//2)\n",
    "    def _Cop(self, x):\n",
    "        return self.blur_transpose(self.blur(x)) + self.beta*x\n",
    "    def forward(self, y):\n",
    "        x = self.blur_transpose(y)\n",
    "        z = x.clone()\n",
    "        mu = torch.zeros_like(x)\n",
    "        for k in range(self.Nunrolled):\n",
    "            # x step\n",
    "            rhs = self.blur_transpose(y)+self.beta*z-mu\n",
    "            x, _ = cg(self._Cop, rhs, self.nitermaxcg)\n",
    "\n",
    "            # z step\n",
    "            z = self.net[k](x+mu/self.beta)\n",
    "\n",
    "            # mu step\n",
    "            mu = mu+self.beta*(x-z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nunrolled = 6\n",
    "nitermaxcg = 15\n",
    "model_admm = DeblurUnrolledADMM(gaussian_kernel, Nunrolled, nitermaxcg, num_chans_net=32).to(device)\n",
    "model_admm.precompute(next(iter(train_loader))[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model_admm.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tblogs/deblurring/unrolled_admm')\n",
    "run(model_admm, optim, train_loader, test_loader, Nepoch=1, verbose=2, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0e20e8976f4aac8f711da61aa93bc459cc2b60abc972a566c8f75c32901bd28"
  },
  "kernelspec": {
   "display_name": "TORCHNUFFT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
